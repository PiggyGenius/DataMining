
# Data mining: $3^{rd}$ practical

### Document classification

#### 1. What is the dimension of the problem (the size of the vocabulary)? What is the number of documents per class (their distribution)?
```{r, echo=FALSE}
library(Matrix)
all_data = readLines("BaseReuters-29", n=100)
rows = length(all_data)
vocab_size = 1000000 # 141144 ?

# TODO : justify structure
# STRUCTURE = sparse matrix + list of classes
words = sparseMatrix(c(1), c(1), x=c(1), dims=c(rows, vocab_size))
classes = vector(,rows)

i = 1
max = 0
for (line in all_data) {
	split = strsplit(line, " ")[[1]]
	classes[i] = as.numeric(split[1])
	for (word in split[-1]) {
		val = as.numeric(strsplit(word, ":")[[1]])
		if (val[1] > max) {
			max = val[1]
		}
		words[i, val[1]] = val[2]
	}
	i = i+1
}

print(max)
```


#### 2. Split randomly the collection into a training set (52500 documents) and a test set (18203 documents).

#### 3. Estimate the parameters of the Bernoulli and the Multinomial models using the training set (following the maximum likelihood approach) and the Laplace smoothing.

#### 4. Estimate the accuracy of both models on the test set.
				     
#### 5. Repeat the steps 2 to 4, 20 times. Estimate the average of the accuracies obtained on the 20 randomly chosen test sets as well as it standard deviation.

					 
