<html><head>                <meta charset="UTF-8" />            <link rel="stylesheet" href="./css/frames.css" type="text/css" /><style type="text/css"> body{margin:50px;}</style></head>            <body dir="ltr"><p>&nbsp;</p><center> <h1>4MMDFASM<br /><span class="commeInput">Data mining and multivariate statistical analysis</span><br />Lab work -  Document classification</h1> </center>    <h2>1. Overall aim</h2><p>Implement the Bernoulli and the Multinomial models and test them over a subset of the <a href="http://trec.nist.gov/data/reuters/reuters.html">REUTERS RCV 1</a>  collection, constituted by  810000 news-wires gathered from August the  20th 1996 until August the 19th 1997 and manually classified into 103  categories.  <br /><br />On Teide, you should provide a .zip or .tar.gz archive containing your code as well as a PDF report.</p>  <h2>2. Development</h2><p>The news-wires are initially in the XML format. We arbitrarily chose 29  categories and 70703 documents from the initial set and  vectorized them  following the Vector Space Model.   <br /> The compressed file containing the associated vectors are available from  <a href="/inp/courses/ENSIMAG4MMFDAS6/document/Labs/BaseReuters-29.bz2">here</a>. <br />  Each line of this file contains the class of a document followed by its  associated vector. In order to optimize the disk storage, the vector is  coded using the index-value format that consists in the index of each  term present in the document as well as its term frequency. For example,  the index-value vector of</p><center> <img src="http://latex.codecogs.com/svg.latex?%5Cvec%7Bv%7D" alt="" border="0" /> = (0 1 0 0 4 0 0 2 0)  </center><p><br /> is :</p><center> <img src="http://latex.codecogs.com/svg.latex?%5Cvec%7Bv%7D_%7Bind-val%7D" alt="" border="0" /> = (2:1 5:4 8:2) </center><p>&nbsp;</p><ol start="1"><li>What is the dimension of the problem (the size of the vocabulary)?  What is the number of documents per class (their distribution)?</li><li>Split randomly the collection into a <i>training</i> set (52500 documents) and a <i>test</i> set (18203 documents).</li><li>Estimate the parameters of the Bernoulli and the Multinomial  models using the training set (following the maximum likelihood  approach) and the  Laplace smoothing.</li><li>Estimate the accuracy of both models on the test set. <br /><br /> <center> Accuracy = <img src="http://latex.codecogs.com/svg.latex?%5Cfrac%7B%5Ctext%7BNumber%20of%20documents%20in%20the%20test%20correctly%20classified%7D%7D%7B%5Ctext%7BSize%20of%20the%20test%20set%7D%7D" alt="" border="0" />  </center><br />&nbsp;</li><li>Repeat the steps 2 to 4, 20 times. Estimate the average of the  accuracies obtained on the 20 randomly chosen test sets as well as it  standard deviation.</li></ol><p>&nbsp;</p></body></html>